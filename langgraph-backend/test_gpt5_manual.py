#!/usr/bin/env python3
"""
Manual GPT-5 Integration Test - Tests the specific complex query from requirements
"""
import os
import json
import asyncio
import aiohttp
import sys
import time

async def test_complex_query():
    """Test the complex query: 'Show me the Breville Barista Express with current pricing and stock levels'"""
    
    query = "Show me the Breville Barista Express with current pricing and stock levels"
    backend_url = "http://localhost:8000"
    
    print(f"ğŸ§ª Testing complex query: {query}")
    print(f"ğŸ¯ Backend URL: {backend_url}")
    print(f"ğŸ” Expected: A2A orchestration involving products, pricing, and inventory agents")
    print("-" * 80)
    
    # Test with auto mode (should detect complexity)
    async with aiohttp.ClientSession() as session:
        payload = {
            "message": query,
            "mode": "auto",
            "thread_id": f"test-complex-{int(time.time())}"
        }
        
        print("ğŸ“¡ Sending request to /api/agent/v2/stream...")
        
        try:
            async with session.post(
                f"{backend_url}/api/agent/v2/stream",
                json=payload
            ) as response:
                if response.status != 200:
                    print(f"âŒ Request failed with status {response.status}")
                    return False
                
                print(f"âœ… Response received with status {response.status}")
                
                # Process streaming response
                full_response = ""
                pattern = None
                agents = []
                a2a_metadata = None
                analysis_reason = None
                
                print("\nğŸ“ Streaming Response:")
                print("-" * 40)
                
                async for line in response.content:
                    line = line.decode('utf-8').strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        event = data.get("event")
                        
                        if event == "conversation_id":
                            pattern = data.get("pattern")
                            analysis_reason = data.get("analysis")
                            print(f"ğŸ§  Complexity Analysis: {pattern}")
                            print(f"ğŸ’­ Reasoning: {analysis_reason}")
                        
                        elif event == "agent_message":
                            agent = data.get("agent")
                            if agent and agent not in agents:
                                agents.append(agent)
                                print(f"ğŸ¤– Agent Active: {agent}")
                            
                            if data.get("tokens"):
                                new_tokens = "".join(data["tokens"])
                                full_response += new_tokens
                                if new_tokens.strip():
                                    print(f"ğŸ’¬ {agent}: {new_tokens}", end="", flush=True)
                        
                        elif event == "a2a_metadata":
                            a2a_metadata = {
                                "execution_path": data.get("execution_path", []),
                                "agents_involved": data.get("agents_involved", []),
                                "a2a_requests": data.get("a2a_requests", [])
                            }
                            print(f"\nğŸ”„ A2A Execution Path: {a2a_metadata['execution_path']}")
                            print(f"ğŸ‘¥ Agents Involved: {a2a_metadata['agents_involved']}")
                        
                        elif event == "done":
                            print(f"\nâœ… Stream completed")
                            break
                        
                        elif event == "error":
                            print(f"\nâŒ Error: {data.get('error')}")
                            return False
                            
                    except json.JSONDecodeError:
                        continue
                
                print("\n" + "-" * 80)
                print("ğŸ“Š RESULTS SUMMARY:")
                print(f"   ğŸ§© Pattern Detected: {pattern}")
                print(f"   ğŸ¤– Agents Used: {' â†’ '.join(agents)}")
                print(f"   ğŸ“ Response Length: {len(full_response)} characters")
                print(f"   âš¡ Contains Pricing Info: {'price' in full_response.lower() or '$' in full_response}")
                print(f"   ğŸ“¦ Contains Stock Info: {'stock' in full_response.lower() or 'inventory' in full_response.lower()}")
                print(f"   â˜• Contains Product Info: {'breville' in full_response.lower() or 'barista' in full_response.lower()}")
                
                if a2a_metadata:
                    print(f"   ğŸ”„ A2A Orchestration: {len(a2a_metadata['a2a_requests'])} requests")
                
                # Success criteria
                success = (
                    pattern in ["a2a", "simple"] and  # Should route appropriately
                    len(full_response) > 50 and       # Should have substantive response
                    len(agents) > 0                   # Should use at least one agent
                )
                
                print(f"\n{'âœ… SUCCESS' if success else 'âŒ FAILURE'}: Test completed")
                
                if full_response:
                    print(f"\nğŸ“‹ FULL RESPONSE:")
                    print("-" * 40)
                    print(full_response)
                    print("-" * 40)
                
                return success
                
        except Exception as e:
            print(f"âŒ Error during test: {e}")
            return False

async def test_provider_usage():
    """Test that the system is actually using GPT-5 models"""
    print("\nğŸ” TESTING GPT-5 MODEL USAGE")
    print("=" * 50)
    
    try:
        sys.path.append('/home/pranav/espressobot/langgraph-backend')
        from app.config.llm_factory import llm_factory
        
        # Test different model tiers
        models_to_test = [
            ("gpt-5", "orchestrator"),
            ("gpt-5-mini", "primary agent"),
            ("gpt-5-nano", "auxiliary agent")
        ]
        
        for model, tier_desc in models_to_test:
            print(f"\nğŸ§ª Testing {model} ({tier_desc})...")
            try:
                llm = llm_factory.create_llm(model, temperature=0.0, max_tokens=50)
                response = llm.invoke(f"Complete this sentence: I am {model} and I")
                
                print(f"   âœ… {model} responded: {response.content[:100]}...")
                
            except Exception as e:
                print(f"   âŒ {model} failed: {e}")
        
        # Test provider configuration
        print(f"\nğŸ“Š Provider Status:")
        print(f"   OpenAI API: {'âœ…' if llm_factory.openai_key else 'âŒ'}")
        print(f"   OpenRouter API: {'âœ…' if llm_factory.openrouter_key else 'âŒ'}")
        print(f"   Anthropic API: {'âœ…' if llm_factory.anthropic_key else 'âŒ'}")
        
    except Exception as e:
        print(f"âŒ Provider test failed: {e}")

async def main():
    """Run manual tests"""
    print("ğŸš€ GPT-5 INTEGRATION MANUAL TESTS")
    print("=" * 50)
    
    # Check backend connectivity
    try:
        import requests
        response = requests.get("http://localhost:8000/health", timeout=5)
        if response.status_code == 200:
            print("âœ… Backend is running and healthy")
        else:
            print(f"âŒ Backend returned status {response.status_code}")
            return
    except Exception as e:
        print(f"âŒ Cannot connect to backend: {e}")
        return
    
    # Test provider usage
    await test_provider_usage()
    
    # Test complex query
    success = await test_complex_query()
    
    print(f"\n{'ğŸ‰ ALL TESTS PASSED' if success else 'âš ï¸ TESTS HAD ISSUES'}")

if __name__ == "__main__":
    asyncio.run(main())